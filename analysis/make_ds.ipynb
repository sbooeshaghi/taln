{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from urllib.error import URLError\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from taln.taln_aln import norm_text, tokenize\n",
    "\n",
    "\n",
    "def nd(arr):\n",
    "    return np.asarray(arr).reshape(-1)\n",
    "\n",
    "\n",
    "def yex(ax):\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "\n",
    "    ax.plot(lims, lims, c=\"k\", alpha=0.75, zorder=0)\n",
    "    ax.set(**{\"aspect\": \"equal\", \"xlim\": lims, \"ylim\": lims})\n",
    "    return ax\n",
    "\n",
    "\n",
    "fsize = 15\n",
    "plt.rcParams.update({\"font.size\": fsize})\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQuAD v2.0\n",
    "# - explorer: https://rajpurkar.github.io/SQuAD-explorer/\n",
    "# - train: https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
    "# - dev: https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
    "\n",
    "DATA_DIR = (Path(\"..\").resolve() / \"data\")\n",
    "SQUAD_URLS = {\n",
    "    \"train\": \"https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\",\n",
    "    \"dev\": \"https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\",\n",
    "}\n",
    "\n",
    "\n",
    "def load_squad_json(split, data_dir=DATA_DIR):\n",
    "    split = split.lower()\n",
    "    if split not in SQUAD_URLS:\n",
    "        raise ValueError(f\"Unknown split: {split}\")\n",
    "\n",
    "    local_path = Path(data_dir) / f\"{split}-v2.0.json\"\n",
    "    if local_path.exists():\n",
    "        with open(local_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    try:\n",
    "        with urlopen(SQUAD_URLS[split]) as resp:\n",
    "            return json.loads(resp.read().decode(\"utf-8\"))\n",
    "    except URLError as e:\n",
    "        raise URLError(\n",
    "            f\"Could not download SQuAD split '{split}'. \"\n",
    "            f\"Either place it at {local_path} or ensure network access.\"\n",
    "        ) from e\n",
    "\n",
    "\n",
    "def squad_to_records(squad_json):\n",
    "    records = []\n",
    "\n",
    "    for article in squad_json[\"data\"]:\n",
    "        title = article.get(\"title\", \"\")\n",
    "        for paragraph in article[\"paragraphs\"]:\n",
    "            source = paragraph[\"context\"]\n",
    "            for qa in paragraph[\"qas\"]:\n",
    "                if qa.get(\"is_impossible\", False):\n",
    "                    continue\n",
    "\n",
    "                question = qa.get(\"question\", \"\")\n",
    "                question_id = qa.get(\"id\", \"\")\n",
    "\n",
    "                for ans in qa.get(\"answers\", []):\n",
    "                    records.append(\n",
    "                        {\n",
    "                            \"title\": title,\n",
    "                            \"source\": source,\n",
    "                            \"target\": ans[\"text\"],\n",
    "                            \"idx_start\": ans[\"answer_start\"],\n",
    "                            \"question\": question,\n",
    "                            \"question_id\": question_id,\n",
    "                            \"is_impossible\": False,\n",
    "                            \"answer_type\": \"answer\",\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "    return records\n",
    "\n",
    "\n",
    "def keep_naive_matches(records):\n",
    "    kept = []\n",
    "\n",
    "    for r in records:\n",
    "        source = r[\"source\"]\n",
    "        target = r[\"target\"]\n",
    "        idx_start = r[\"idx_start\"]\n",
    "\n",
    "        if not isinstance(source, str) or not isinstance(target, str):\n",
    "            continue\n",
    "        if not isinstance(idx_start, int) or idx_start < 0:\n",
    "            continue\n",
    "\n",
    "        if source.find(target) != idx_start:\n",
    "            continue\n",
    "\n",
    "        kept.append(r)\n",
    "\n",
    "    return kept\n",
    "\n",
    "\n",
    "def dedupe_records(records):\n",
    "    seen = set()\n",
    "    out = []\n",
    "\n",
    "    for r in records:\n",
    "        key = (r[\"source\"], r[\"target\"], r[\"idx_start\"])\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        out.append(r)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def add_row_id(records):\n",
    "    out = []\n",
    "\n",
    "    for i, r in enumerate(records):\n",
    "        rr = dict(r)\n",
    "        rr[\"row_id\"] = i\n",
    "        out.append(rr)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def shift_records(records):\n",
    "    out = []\n",
    "\n",
    "    for r in records:\n",
    "        rr = dict(r)\n",
    "        idx_start = rr[\"idx_start\"]\n",
    "        source = rr[\"source\"]\n",
    "\n",
    "        rr[\"idx_start_orig\"] = idx_start\n",
    "        rr[\"target_orig\"] = rr[\"target\"]\n",
    "\n",
    "        if idx_start > 0 and source[idx_start - 1] == \" \":\n",
    "            rr[\"target\"] = \" \" + rr[\"target\"]\n",
    "            rr[\"idx_start\"] = idx_start - 1\n",
    "\n",
    "        out.append(rr)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def build_boat_frames(clean_records, shifted_records, min_target_ws_tokens=2):\n",
    "    cols = [\"title\", \"question\", \"question_id\", \"is_impossible\", \"answer_type\"]\n",
    "    clean_df = pd.DataFrame(clean_records)\n",
    "    shifted_df = pd.DataFrame(shifted_records)\n",
    "\n",
    "    shifted_df = shifted_df[shifted_df[\"target\"].str.split().str.len() > min_target_ws_tokens]\n",
    "    keep_ids = set(shifted_df[\"row_id\"].tolist())\n",
    "    clean_df = clean_df[clean_df[\"row_id\"].isin(keep_ids)]\n",
    "\n",
    "    tdf = (\n",
    "        shifted_df.drop(columns=cols, errors=\"ignore\")\n",
    "        .groupby([\"source\", \"target\"])[\"idx_start\"]\n",
    "        .apply(set)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    wdf = (\n",
    "        clean_df.drop(columns=cols, errors=\"ignore\")\n",
    "        .groupby([\"source\", \"target\"])[\"idx_start\"]\n",
    "        .apply(set)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    return wdf, tdf, clean_df.reset_index(drop=True), shifted_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: dropped 7705 records where norm_text changes string length\n",
      "dev: dropped 794 records where norm_text changes string length\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((30767, 3), (30767, 3), (4313, 3), (4313, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_split(split):\n",
    "    squad_json = load_squad_json(split)\n",
    "    raw_records = squad_to_records(squad_json)\n",
    "\n",
    "    n_raw = len(raw_records)\n",
    "\n",
    "    clean_records = keep_naive_matches(raw_records)\n",
    "    n_naive = len(clean_records)\n",
    "\n",
    "    clean_records = dedupe_records(clean_records)\n",
    "    n_dedup = len(clean_records)\n",
    "\n",
    "    # token offsets are computed on normalized text; if normalization changes length,\n",
    "    # character indices may no longer be comparable.\n",
    "    def len_preserved(r):\n",
    "        return len(norm_text(r[\"source\"])) == len(r[\"source\"]) and len(norm_text(r[\"target\"])) == len(r[\"target\"])\n",
    "\n",
    "    clean_records = [r for r in clean_records if len_preserved(r)]\n",
    "    n_len_ok = len(clean_records)\n",
    "\n",
    "    if n_len_ok < n_dedup:\n",
    "        print(f\"{split}: dropped {n_dedup - n_len_ok} records where norm_text changes string length\")\n",
    "\n",
    "    clean_records = add_row_id(clean_records)\n",
    "    shifted_records = shift_records(clean_records)\n",
    "\n",
    "    n_shifted = sum(r[\"idx_start\"] != r[\"idx_start_orig\"] for r in shifted_records)\n",
    "\n",
    "    wdf, tdf, clean_df, shifted_df = build_boat_frames(\n",
    "        clean_records,\n",
    "        shifted_records,\n",
    "        min_target_ws_tokens=2,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"n_raw\": n_raw,\n",
    "        \"n_naive\": n_naive,\n",
    "        \"n_dedup\": n_dedup,\n",
    "        \"n_len_ok\": n_len_ok,\n",
    "        \"n_shifted\": n_shifted,\n",
    "        \"clean_df\": clean_df,\n",
    "        \"shifted_df\": shifted_df,\n",
    "        \"wdf\": wdf,\n",
    "        \"tdf\": tdf,\n",
    "    }\n",
    "\n",
    "\n",
    "train = build_split(\"train\")\n",
    "dev = build_split(\"dev\")\n",
    "\n",
    "wdf_train, tdf_train = train[\"wdf\"], train[\"tdf\"]\n",
    "wdf_dev, tdf_dev = dev[\"wdf\"], dev[\"tdf\"]\n",
    "\n",
    "wdf_train.shape, tdf_train.shape, wdf_dev.shape, tdf_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>idx_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nA gene is a locus (or region) of DNA that en...</td>\n",
       "      <td>The transmission of genes to an organism's of...</td>\n",
       "      <td>{135}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nA gene is a locus (or region) of DNA that en...</td>\n",
       "      <td>a locus (or region) of DNA that encodes a fun...</td>\n",
       "      <td>{10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nA gene is a locus (or region) of DNA that en...</td>\n",
       "      <td>blood type, risk for specific diseases, or th...</td>\n",
       "      <td>{479}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nA gene is a locus (or region) of DNA that en...</td>\n",
       "      <td>eye colour or number of limbs</td>\n",
       "      <td>{422}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nA gene is a locus (or region) of DNA that en...</td>\n",
       "      <td>polygenes (many different genes)</td>\n",
       "      <td>{292}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  \\nA gene is a locus (or region) of DNA that en...   \n",
       "1  \\nA gene is a locus (or region) of DNA that en...   \n",
       "2  \\nA gene is a locus (or region) of DNA that en...   \n",
       "3  \\nA gene is a locus (or region) of DNA that en...   \n",
       "4  \\nA gene is a locus (or region) of DNA that en...   \n",
       "\n",
       "                                              target idx_start  \n",
       "0   The transmission of genes to an organism's of...     {135}  \n",
       "1   a locus (or region) of DNA that encodes a fun...      {10}  \n",
       "2   blood type, risk for specific diseases, or th...     {479}  \n",
       "3                      eye colour or number of limbs     {422}  \n",
       "4                   polygenes (many different genes)     {292}  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_raw</th>\n",
       "      <th>n_naive</th>\n",
       "      <th>n_dedup</th>\n",
       "      <th>n_len_ok</th>\n",
       "      <th>n_shifted</th>\n",
       "      <th>n_clean_rows</th>\n",
       "      <th>n_shift_rows</th>\n",
       "      <th>n_clean_span_bad</th>\n",
       "      <th>n_shift_span_bad</th>\n",
       "      <th>shift_rule_ok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>86821</td>\n",
       "      <td>83916</td>\n",
       "      <td>81260</td>\n",
       "      <td>73555</td>\n",
       "      <td>68528</td>\n",
       "      <td>30767</td>\n",
       "      <td>30767</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dev</th>\n",
       "      <td>20302</td>\n",
       "      <td>19291</td>\n",
       "      <td>9451</td>\n",
       "      <td>8657</td>\n",
       "      <td>8172</td>\n",
       "      <td>4313</td>\n",
       "      <td>4313</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_raw n_naive n_dedup n_len_ok n_shifted n_clean_rows n_shift_rows  \\\n",
       "train  86821   83916   81260    73555     68528        30767        30767   \n",
       "dev    20302   19291    9451     8657      8172         4313         4313   \n",
       "\n",
       "      n_clean_span_bad n_shift_span_bad shift_rule_ok  \n",
       "train                0                0          True  \n",
       "dev                  0                0          True  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_span_mismatches(df, source_col=\"source\", target_col=\"target\", idx_col=\"idx_start\"):\n",
    "    bad = []\n",
    "\n",
    "    for i, r in df.iterrows():\n",
    "        source = r[source_col]\n",
    "        target = r[target_col]\n",
    "        idx_start = r[idx_col]\n",
    "\n",
    "        if source[idx_start : idx_start + len(target)] != target:\n",
    "            bad.append(i)\n",
    "\n",
    "    return bad\n",
    "\n",
    "\n",
    "def check_shift_rule(shifted_df):\n",
    "    shifted = shifted_df[shifted_df[\"idx_start\"] != shifted_df[\"idx_start_orig\"]]\n",
    "    if shifted.shape[0] == 0:\n",
    "        return True\n",
    "\n",
    "    def row_ok(r):\n",
    "        idx0 = r[\"idx_start_orig\"]\n",
    "        if idx0 <= 0:\n",
    "            return False\n",
    "        if r[\"source\"][idx0 - 1] != \" \":\n",
    "            return False\n",
    "        if r[\"idx_start\"] != idx0 - 1:\n",
    "            return False\n",
    "        return r[\"target\"] == \" \" + r[\"target_orig\"]\n",
    "\n",
    "    return shifted.apply(row_ok, axis=1).all()\n",
    "\n",
    "\n",
    "def summarize_split(split_obj):\n",
    "    clean_df = split_obj[\"clean_df\"]\n",
    "    shifted_df = split_obj[\"shifted_df\"]\n",
    "\n",
    "    clean_bad = find_span_mismatches(clean_df)\n",
    "    shifted_bad = find_span_mismatches(shifted_df)\n",
    "\n",
    "    return {\n",
    "        \"n_raw\": split_obj[\"n_raw\"],\n",
    "        \"n_naive\": split_obj[\"n_naive\"],\n",
    "        \"n_dedup\": split_obj[\"n_dedup\"],\n",
    "        \"n_len_ok\": split_obj[\"n_len_ok\"],\n",
    "        \"n_shifted\": split_obj[\"n_shifted\"],\n",
    "        \"n_clean_rows\": clean_df.shape[0],\n",
    "        \"n_shift_rows\": shifted_df.shape[0],\n",
    "        \"n_clean_span_bad\": len(clean_bad),\n",
    "        \"n_shift_span_bad\": len(shifted_bad),\n",
    "        \"shift_rule_ok\": bool(check_shift_rule(shifted_df)),\n",
    "    }\n",
    "\n",
    "\n",
    "checks = pd.DataFrame({\"train\": summarize_split(train), \"dev\": summarize_split(dev)}).T\n",
    "checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_sources    13680\n",
       "train_targets    29751\n",
       "train_pairs      30767\n",
       "dev_sources       1021\n",
       "dev_targets       4259\n",
       "dev_pairs         4313\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(\n",
    "    {\n",
    "        \"train_sources\": tdf_train[\"source\"].nunique(),\n",
    "        \"train_targets\": tdf_train[\"target\"].nunique(),\n",
    "        \"train_pairs\": tdf_train.shape[0],\n",
    "        \"dev_sources\": tdf_dev[\"source\"].nunique(),\n",
    "        \"dev_targets\": tdf_dev[\"target\"].nunique(),\n",
    "        \"dev_pairs\": tdf_dev.shape[0],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_texts(texts):\n",
    "    chars = texts.str.len()\n",
    "    ws = texts.apply(lambda s: len(s.split()))\n",
    "    toks = texts.apply(lambda s: len(tokenize(s)[0]))\n",
    "\n",
    "    return {\n",
    "        \"Char/Sample\": chars.mean(),\n",
    "        \"WS/Sample\": ws.mean(),\n",
    "        \"Tok/Sample\": toks.mean(),\n",
    "        \"N Samples\": texts.shape[0],\n",
    "    }\n",
    "\n",
    "\n",
    "def boat_summary_table(tdf):\n",
    "    sources = pd.Series(tdf[\"source\"].unique())\n",
    "    targets = pd.Series(tdf[\"target\"].unique())\n",
    "\n",
    "    table = pd.DataFrame(\n",
    "        {\n",
    "            \"source\": summarize_texts(sources),\n",
    "            \"target\": summarize_texts(targets),\n",
    "        }\n",
    "    ).T\n",
    "\n",
    "    return table[[\"N Samples\", \"Char/Sample\", \"WS/Sample\", \"Tok/Sample\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = boat_summary_table(pd.concat([tdf_train, tdf_dev]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      " & N Samples & Char/Sample & WS/Sample & Tok/Sample \\\\\n",
      "\\midrule\n",
      "source & 14701 & 744 & 118 & 154 \\\\\n",
      "target & 33897 & 39 & 6 & 8 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(summary.to_latex(float_format=\"%.0f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>N Samples</th>\n",
       "      <th>Char/Sample</th>\n",
       "      <th>WS/Sample</th>\n",
       "      <th>Tok/Sample</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th>text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">train</th>\n",
       "      <th>source</th>\n",
       "      <td>13680.0</td>\n",
       "      <td>739.211</td>\n",
       "      <td>117.053</td>\n",
       "      <td>153.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>29751.0</td>\n",
       "      <td>38.337</td>\n",
       "      <td>5.917</td>\n",
       "      <td>7.694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dev</th>\n",
       "      <th>source</th>\n",
       "      <td>1021.0</td>\n",
       "      <td>809.574</td>\n",
       "      <td>127.489</td>\n",
       "      <td>164.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>4259.0</td>\n",
       "      <td>39.706</td>\n",
       "      <td>6.069</td>\n",
       "      <td>7.557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              N Samples  Char/Sample  WS/Sample  Tok/Sample\n",
       "split text                                                 \n",
       "train source    13680.0      739.211    117.053     153.640\n",
       "      target    29751.0       38.337      5.917       7.694\n",
       "dev   source     1021.0      809.574    127.489     164.746\n",
       "      target     4259.0       39.706      6.069       7.557"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl = pd.concat({\"train\": tbl_train, \"dev\": tbl_dev}, names=[\"split\", \"text\"]).round(3)\n",
    "tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      " & N Samples & Char/Sample & WS/Sample & Tok/Sample \\\\\n",
      "\\midrule\n",
      "source & 13680 & 739 & 117 & 154 \\\\\n",
      "target & 29751 & 38 & 6 & 8 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tbl_train.to_latex(float_format=\"%.0f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boat_train.tdf.json': '/Users/sinabooeshaghi/projects/taln/data/boat_train.tdf.json',\n",
       " 'boat_train.wdf.json': '/Users/sinabooeshaghi/projects/taln/data/boat_train.wdf.json',\n",
       " 'boat_dev.tdf.json': '/Users/sinabooeshaghi/projects/taln/data/boat_dev.tdf.json',\n",
       " 'boat_dev.wdf.json': '/Users/sinabooeshaghi/projects/taln/data/boat_dev.wdf.json'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_jsonable_starts(df):\n",
    "    out = df.copy()\n",
    "    out[\"idx_start\"] = out[\"idx_start\"].apply(lambda s: sorted(list(s)))\n",
    "    return out\n",
    "\n",
    "\n",
    "def write_boat_files(data_dir=DATA_DIR):\n",
    "    data_dir = Path(data_dir)\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    exports = {\n",
    "        \"boat_train.tdf.json\": to_jsonable_starts(tdf_train),\n",
    "        \"boat_train.wdf.json\": to_jsonable_starts(wdf_train),\n",
    "        \"boat_dev.tdf.json\": to_jsonable_starts(tdf_dev),\n",
    "        \"boat_dev.wdf.json\": to_jsonable_starts(wdf_dev),\n",
    "    }\n",
    "\n",
    "    for name, df in exports.items():\n",
    "        path = data_dir / name\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(df.to_dict(orient=\"records\"), f)\n",
    "\n",
    "    return {k: str(Path(data_dir) / k) for k in exports}\n",
    "\n",
    "\n",
    "written = write_boat_files()\n",
    "written\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn =  keep_naive_matches(squad_to_records(load_squad_json(\"train\")))\n",
    "dev =  keep_naive_matches(squad_to_records(load_squad_json(\"dev\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>idx_start</th>\n",
       "      <th>question</th>\n",
       "      <th>question_id</th>\n",
       "      <th>is_impossible</th>\n",
       "      <th>answer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49370</th>\n",
       "      <td>Alsace</td>\n",
       "      <td>\"Alsatia\", the Latin form of Alsace's name, ha...</td>\n",
       "      <td>a lawless place\" or \"a place under no jurisdic...</td>\n",
       "      <td>119</td>\n",
       "      <td>What is the meaning of the name Aslatia in Eng...</td>\n",
       "      <td>5727acde3acd2414000de95d</td>\n",
       "      <td>False</td>\n",
       "      <td>answer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        title                                             source  \\\n",
       "49370  Alsace  \"Alsatia\", the Latin form of Alsace's name, ha...   \n",
       "\n",
       "                                                  target  idx_start  \\\n",
       "49370  a lawless place\" or \"a place under no jurisdic...        119   \n",
       "\n",
       "                                                question  \\\n",
       "49370  What is the meaning of the name Aslatia in Eng...   \n",
       "\n",
       "                    question_id  is_impossible answer_type  \n",
       "49370  5727acde3acd2414000de95d          False      answer  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([pd.DataFrame(trn), pd.DataFrame(dev)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt = df[df.target.str.contains(\"a place under no jurisdiction\")].iloc[0].target\n",
    "src = df[df.target.str.contains(\"a place under no jurisdiction\")].iloc[0].source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt in src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a lawless place\" or \"a place under no jurisdiction'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Alsatia\", the Latin form of Alsace\\'s name, has long ago entered the English language with the specialized meaning of \"a lawless place\" or \"a place under no jurisdiction\" - since Alsace was conceived by English people to be such. It was used into the 20th century as a term for a ramshackle marketplace, \"protected by ancient custom and the independence of their patrons\". As of 2007, the word is still in use among the English and Australian judiciaries with the meaning of a place where the law cannot reach: \"In setting up the Serious Organised Crime Agency, the state has set out to create an Alsatia - a region of executive action free of judicial oversight,\" Lord Justice Sedley in UMBS v SOCA 2007.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                                                       Alsace\n",
       "source           \"Alsatia\", the Latin form of Alsace's name, ha...\n",
       "target           a lawless place\" or \"a place under no jurisdic...\n",
       "idx_start                                                      119\n",
       "question         What is the meaning of the name Aslatia in Eng...\n",
       "question_id                               5727acde3acd2414000de95d\n",
       "is_impossible                                                False\n",
       "answer_type                                                 answer\n",
       "Name: 49370, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.target.str.contains(\"a place under no jurisdiction\")].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
